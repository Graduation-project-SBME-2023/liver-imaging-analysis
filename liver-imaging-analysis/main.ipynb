{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22083,"status":"ok","timestamp":1671796117028,"user":{"displayName":"Muhammad Al-Barbary","userId":"17995394362028937160"},"user_tz":-120},"id":"7MqM5G59bEsX","outputId":"6fe415b7-ee79-4adc-b8cf-a92463e3aa09"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13387,"status":"ok","timestamp":1671796154451,"user":{"displayName":"Muhammad Al-Barbary","userId":"17995394362028937160"},"user_tz":-120},"id":"5e7SWTFFDBcD","outputId":"5e999f78-cce3-4195-b262-15af693c9b4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting monai\n","  Downloading monai-1.1.0-202212191849-py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 28.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from monai) (1.21.6)\n","Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.8/dist-packages (from monai) (1.13.0+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.8->monai) (4.4.0)\n","Installing collected packages: monai\n","Successfully installed monai-1.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (0.18.3)\n","Collecting scikit-image\n","  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n","\u001b[K     |████████████████████████████████| 14.0 MB 21.1 MB/s \n","\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (7.1.2)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.7.3)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2022.10.10)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.9.0)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.8.8)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.21.6)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image) (3.0.9)\n","Installing collected packages: scikit-image\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.18.3\n","    Uninstalling scikit-image-0.18.3:\n","      Successfully uninstalled scikit-image-0.18.3\n","Successfully installed scikit-image-0.19.3\n"]}],"source":["!pip install monai\n","!pip install -U scikit-image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b0XUOIgOCzD7"},"outputs":[],"source":["# !pip install torchvision\n","# !pip install torch\n","# !pip install matplotlib\n","# !pip install monai\n","# !pip install nibabel\n","# !pip install -U scikit-learn scipy matplotlib\n","# !pip install -U numpy \n","# !pip install tensorboard"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1671797021480,"user":{"displayName":"Muhammad Al-Barbary","userId":"17995394362028937160"},"user_tz":-120},"id":"kBaDMI4jbzih"},"outputs":[],"source":["import sys\n","import os\n","py_file_location = \"/content/drive/MyDrive/liver-imaging-analysis/engine\"\n","sys.path.append(os.path.abspath(py_file_location))\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(512, 512)\n"]}],"source":["from PIL import Image\n","import numpy\n","img = Image.open(\"C:/Users/Muhammad Al-Barbary/OneDrive/Desktop/Education/Year4/Graduation Project/Project Repository/liver-imaging-analysis/liver-imaging-analysis/models/Temp2D/volume/liver-orig002_0.png\")\n","print(numpy.array(img).shape)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"elapsed":120763,"status":"error","timestamp":1671797262426,"user":{"displayName":"Muhammad Al-Barbary","userId":"17995394362028937160"},"user_tz":-120},"id":"aW_HEcfAb9ni","outputId":"c7b87171-02a8-4036-fd4a-3d29caad0b72"},"outputs":[{"name":"stdout","output_type":"stream","text":["Used Device:  cuda\n"]},{"ename":"AssertionError","evalue":"Torch not compiled with CUDA enabled","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# import torch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# import nibabel\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# import engine\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39m# from torch import nn\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# import losses\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mliver_segmentation\u001b[39;00m \u001b[39mimport\u001b[39;00m segment_liver\n\u001b[0;32m      9\u001b[0m segment_liver()\n\u001b[0;32m     11\u001b[0m \u001b[39m# #Read configurations from JSON File\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m# with open('../config/configs.json') as f:\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#     config = json.load(f)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m# output=model.predict(ImagePath)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# output.shape\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Tarek\\Documents\\GitHub\\liver-imaging-analysis\\liver-imaging-analysis\\models\\liver_segmentation.py:112\u001b[0m\n\u001b[0;32m     82\u001b[0m             transforms\u001b[39m=\u001b[39m {\n\u001b[0;32m     83\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m3DUnet_transform\u001b[39m\u001b[39m'\u001b[39m: Compose(\n\u001b[0;32m     84\u001b[0m                 [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m             )\n\u001b[0;32m    109\u001b[0m             } \n\u001b[0;32m    110\u001b[0m             \u001b[39mreturn\u001b[39;00m transforms[transform_name]     \n\u001b[1;32m--> 112\u001b[0m model\u001b[39m=\u001b[39mLiverSegmentation()\n\u001b[0;32m    113\u001b[0m model\u001b[39m.\u001b[39mdata_status()\n\u001b[0;32m    114\u001b[0m model\u001b[39m.\u001b[39mfit()\n","File \u001b[1;32mc:\\Users\\Tarek\\Documents\\GitHub\\liver-imaging-analysis\\liver-imaging-analysis\\engine\\engine.py:33\u001b[0m, in \u001b[0;36mEngine.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mUsed Device: \u001b[39m\u001b[39m\"\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     25\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_loss(\n\u001b[0;32m     26\u001b[0m     loss_name\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mloss_function\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_network(\n\u001b[0;32m     31\u001b[0m     network_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnetwork_name,\n\u001b[0;32m     32\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnetwork_parameters\n\u001b[1;32m---> 33\u001b[0m     )\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m     36\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_optimizer(\n\u001b[0;32m     37\u001b[0m     optimizer_name \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39moptimizer,\n\u001b[0;32m     38\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig\u001b[39m.\u001b[39moptimizer_parameters\n\u001b[0;32m     39\u001b[0m     )\n\u001b[0;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_data()\n","File \u001b[1;32mc:\\Users\\Tarek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:987\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    984\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n","File \u001b[1;32mc:\\Users\\Tarek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:639\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    638\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 639\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    641\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    642\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    643\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    644\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    650\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Tarek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:639\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    638\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 639\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    641\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    642\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    643\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    644\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    650\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Tarek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:662\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 662\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    663\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    664\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n","File \u001b[1;32mc:\\Users\\Tarek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:985\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    982\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    983\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    984\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 985\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n","File \u001b[1;32mc:\\Users\\Tarek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\cuda\\__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n","\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"]}],"source":["# import torch\n","# import nibabel\n","# import engine\n","# import models\n","# import json\n","# from torch import nn\n","# import losses\n","from models.liver_segmentation import segment_liver\n","segment_liver()\n","\n","# #Read configurations from JSON File\n","# with open('../config/configs.json') as f:\n","#     config = json.load(f)\n","\n","# %load_ext tensorboard\n","# # %tensorboard --logdir \"/content/drive/MyDrive/liver-imaging-analysis/engine/runs/\"\n","\n","# #Instance from the Model\n","# model= engine.Engine()\n","\n","# #Print loss function, optimizer, and metrics\n","# print(\"Compile Status\")\n","# print(\"-------------------------------\")\n","# model.compile_status()\n","\n","# #Print Dataset Shape\n","# print(\"\\nData Status\")\n","# print(\"-------------------------------\")\n","# model.data_status()\n","\n","# # Load Stored Checkpoint\n","# model.load_checkpoint(config['potential_checkpoint'])\n","\n","# # Start Fitting\n","# print(\"\\nTraining\")\n","# print(\"-------------------------------\")\n","# model.fit(\n","#     epochs=config[\"training\"]['epochs'],\n","#     evaluation_set=model.test_dataloader,\n","#     evaluate_epochs=1,\n","#     visualize_epochs=1,\n","#     save_flag=True,\n","#     save_path=config[\"potential_checkpoint\"]\n","# )\n","\n","# # #Test model on testing set\n","# print(\"\\nTesting\")\n","# print(\"-------------------------------\")\n","# print(\"Training loss=\",model.test(model.train_dataloader))\n","# print(\"Testing loss=\",model.test(model.test_dataloader))\n","\n","#Predict mask for a single volume\n","# print(\"\\nPrediction\")\n","# print(\"-------------------------------\")\n","# ImagePath=config['ImagePath']\n","# output=model.predict(ImagePath)\n","# output.shape\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xd2QCRkVcV6h"},"outputs":[],"source":["# #if model is better, update checkpoint:\n","# model.save_checkpoint(config[\"model_checkpoint\"])"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"},"vscode":{"interpreter":{"hash":"60f38b465b4ade997603fa1c81d4c5b7ecf3a62a523ec595fe3d6f4efcae3a4f"}}},"nbformat":4,"nbformat_minor":0}
