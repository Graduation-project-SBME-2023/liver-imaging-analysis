{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d3fd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision # torch package for vision related things\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn  # All neural network modules\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import os \n",
    "# Gives easier dataset managment by creating mini batches etc.\n",
    "from tqdm import tqdm  # For nice progress bar!\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nibabel.testing import data_path\n",
    "import os\n",
    "import nibabel as nib\n",
    "import cv2 as cv\n",
    "from nibabel.testing import data_path\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from monai.transforms import LoadImageD\n",
    "from monai.transforms import \\\n",
    "    LoadImageD, EnsureChannelFirstD, AddChannelD, ScaleIntensityD, ToTensorD, Compose,NormalizeIntensityD, \\\n",
    "    AsDiscreteD, SpacingD, OrientationD, ResizeD, RandSpatialCropd, Spacingd,RandFlipd, RandScaleIntensityd,RandShiftIntensityd, \\\n",
    "    RandSpatialCropd, RandRotated\n",
    "import monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "989bf502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize global variables \n",
    "\n",
    "roi_size=[500, 500, 30]\n",
    "# Paths = {\"Barbary\":\"C:/dataset\", }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d66f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS=(\"image\", \"label\")\n",
    "\n",
    "class preprocessing():\n",
    "    def __init__(self, KEYS=(\"image\", \"label\"), size=[500, 500, 30]):\n",
    "        r\"\"\"A Class that preprocesses data\n",
    "            __init__\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            KEYS : Dictionary labels for image and mask\n",
    "\n",
    "            size : 3d array of the wanted volume size \n",
    "                The type above can either refer to an actual Python type\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            No returns\n",
    "\n",
    "          \"\"\"\n",
    "        self.transform = Compose([\n",
    "            EnsureChannelFirstD(KEYS),\n",
    "#             AddChannelD(\"label\"), #assumes label is not rgb - will need to manually implement a class for multiple segments\n",
    "            OrientationD(KEYS, axcodes='LAS'), #preferred by radiologists\n",
    "            SpacingD(KEYS, pixdim=(1., 1., 1.), mode=('bilinear', 'nearest')),\n",
    "            ResizeD(KEYS, size , mode=('trilinear', 'nearest')),\n",
    "            RandFlipd(KEYS, prob=0.5, spatial_axis=1),\n",
    "            RandRotated(KEYS, range_x=0.1, range_y=0.1, range_z=0.1, prob=0.5, keep_size=True),\n",
    "            RandScaleIntensityd(keys=\"image\", factors=0.1, prob=0.5),\n",
    "            RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=0.5),\n",
    "            NormalizeIntensityD(KEYS, channel_wise=True), #normalize intensity to have mean = 0 and std = 1.\n",
    "            ToTensorD(KEYS),\n",
    "        ])\n",
    "    def __call__(self,data_dict):\n",
    "        r\"\"\"__call__\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            data_dict : Dictionary of paths for images and masks\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            \n",
    "            data_dict : Dictionary\n",
    "                the dictionary containing data after applying transformations.\n",
    "           \n",
    "          \"\"\"\n",
    "        data_dict = self.transform(data_dict)\n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f188ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calling preprocessing\n",
    "\n",
    "\n",
    "# ## load \n",
    "# dict_loader = LoadImageD(keys=(\"image\", \"label\"))\n",
    "# data_dict = dict_loader({\"image\": 'D:/GP/MSD/Path/hepaticvessel_051.nii' ,\n",
    "#                          \"label\": 'D:/GP/MSD/Path/hepaticvessel_051.nii'})\n",
    "# # ## plot\n",
    "# print(f\"image shape: {data_dict['image'].shape}, \\nlabel shape: {data_dict['label'].shape}\")\n",
    "# print(f\"mean is : { np.mean(data_dict['image'],dtype=np.float64) } \")\n",
    "# print(f\"std is : { np.std(data_dict['image'],dtype=np.float64)}\")\n",
    "    \n",
    "# # ##preprocess##    \n",
    "\n",
    "# preprocess = preprocessing(KEYS, roi_size)\n",
    "# data_dict_processed = preprocess(data_dict)\n",
    "\n",
    "# print(\"*********\")\n",
    "# print(f\"tansformed image shape: {data_dict_processed['image'].shape}, \\ntransformed label shape: {data_dict_processed['label'].shape}\")\n",
    "# print(f\"mean is: {np.mean(data_dict_processed['image'],dtype=np.float64)} \")\n",
    "# print(f\"std is : {np.std(data_dict_processed['image'],dtype=np.float64)}\")\n",
    "\n",
    "\n",
    "# f, ax = plt.subplots(1,2)\n",
    "\n",
    "# ax[0].imshow(data_dict[\"image\"][:,:,29])\n",
    "# ax[0].title.set_text('Original')\n",
    "\n",
    "# ax[1].imshow(data_dict_processed[\"image\"][0,:,:,29])\n",
    "# ax[1].title.set_text('Transformed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26ed94d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomData(Dataset):\n",
    "    def __init__(self, volume_dir, mask_dir, volumeNames, maskNames, KEYS=(\"image\", \"label\") ,roi_size=[500, 500, 30], \n",
    "                 transform = False):\n",
    "       \n",
    "        r\"\"\"__init__\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            volume_dir : string\n",
    "                directory for all the volumes.\n",
    "\n",
    "            volumeNames : Arr \n",
    "                Array of names inside the volume directory.\n",
    "            \n",
    "            mask_dir : string\n",
    "                directory for all the masks\n",
    "\n",
    "            maskNames : string \n",
    "                Array of names inside the mask directorymask.\n",
    "            \n",
    "            KEYS : Dictionary labels for image and mask.\n",
    "\n",
    "            roi_size : 3d array of the wanted volume size \n",
    "                The type above can either refer to an actual Python type.\n",
    "                \n",
    "            transform: boolean\n",
    "                 Set true if you want to preprocess the data.\n",
    "                 \n",
    "            Returns\n",
    "            -------\n",
    "            No returns\n",
    "            \n",
    "        \"\"\"\n",
    " \n",
    "        \n",
    "        self.volume_dir = volume_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.volumeNames = volumeNames\n",
    "        self.maskNames=maskNames\n",
    "        self.keys = KEYS\n",
    "\n",
    "        #transforms from monai transform lib \n",
    "        self.transform = transform\n",
    "        self.preprocess = preprocessing(KEYS, roi_size)\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        r\"\"\"__len__\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            no params \n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            \n",
    "            data length : int\n",
    "                Length of the whole dataset\n",
    "           \n",
    "          \"\"\"\n",
    "        return len(self.volumeNames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        r\"\"\"__getitem__\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            index : int \n",
    "                index of the required volume and mask\n",
    "            Returns\n",
    "            -------\n",
    "            \n",
    "            data_dict : dictionary\n",
    "                Containing the volume as the image and the mask as the label\n",
    "           \n",
    "          \"\"\"\n",
    "        \n",
    "               \n",
    "        volume_path = os.path.join(self.volume_dir, self.volumeNames[index])\n",
    "        mask_path = os.path.join(self.mask_dir, self.maskNames[index])\n",
    "         \n",
    "        dict_loader = LoadImageD(keys=self.keys)\n",
    "        data_dict = dict_loader({self.keys[0]: volume_path ,\n",
    "                                 self.keys[1]: mask_path})\n",
    "        if self.transform == True:\n",
    "            data_dict = self.preprocess(data_dict) \n",
    "        \n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b65f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, Paths,dataset_name, batch_size, num_workers=0, pin_memory=False , test_size=0.15, Transform = False,\n",
    "                 Keys=(\"image\", \"label\"),size=[500, 500, 30]):\n",
    "        \n",
    "        r\"\"\"__init__\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            dataset_name: string\n",
    "                name of the dataset to be loaded eg \"MSD\" or \"MED_seg\"\n",
    "                \n",
    "            batch_size: int\n",
    "                size of batches to be returned    \n",
    "            \n",
    "            test_size : float\n",
    "                proportion of the test size \n",
    "                \n",
    "            transform: boolean\n",
    "                 Set true if you want to preprocess the data.\n",
    "                 \n",
    "            volumeNames : Arr \n",
    "                Array of names inside the volume directory.\n",
    "            \n",
    "            Keys : Dictionary labels for image and mask.\n",
    "\n",
    "            size : 3d array of the wanted volume size \n",
    "                The type above can either refer to an actual Python type.\n",
    "                \n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            No returns\n",
    "            \n",
    "            Other Parameters\n",
    "            ----------------\n",
    "             num_workers : int, optional\n",
    "                set by default to 0\n",
    "            \n",
    "             pin_memory : boolean, optional\n",
    "                set by default to False\n",
    "\n",
    "          \"\"\"\n",
    "        \n",
    "        print(Paths[dataset_name])\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "        \n",
    "        self.volume_dir = os.path.join(Paths[dataset_name], \"Path\")\n",
    "        self.mask_dir = os.path.join(Paths[dataset_name], \"Path2\")\n",
    "       \n",
    "        self.volumeNames = os.listdir(self.volume_dir)\n",
    "        self.maskNames=os.listdir(self.mask_dir)\n",
    "        \n",
    "        test_size = int(test_size * len(self.volumeNames))\n",
    "        train_size = len(self.volumeNames)-test_size\n",
    "        \n",
    "        self.train_volumeNames, self.test_volumeNames = torch.utils.data.random_split(self.volumeNames, [train_size, test_size])\n",
    "        self.train_maskNames, self.test_maskNames = torch.utils.data.random_split(self.maskNames, [train_size, test_size])\n",
    "        \n",
    "        \n",
    "        self.train_ds = CustomData(\n",
    "        volume_dir=self.volume_dir,\n",
    "        mask_dir=self.mask_dir,\n",
    "        volumeNames =  self.train_volumeNames, \n",
    "        maskNames =  self.train_maskNames,\n",
    "        transform=Transform,\n",
    "        KEYS=Keys,\n",
    "        roi_size = size\n",
    "        )\n",
    "        \n",
    "        self.test_ds = CustomData(\n",
    "        volume_dir=self.volume_dir,\n",
    "        mask_dir=self.mask_dir,\n",
    "        volumeNames =  self.test_volumeNames, \n",
    "        maskNames =  self.test_maskNames,\n",
    "        transform=Transform,\n",
    "        KEYS=Keys,\n",
    "        roi_size = size\n",
    "        )\n",
    "        \n",
    "    def get_training_data(self):\n",
    "        \n",
    "        r\"\"\"get_training_data\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            None\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            train_loader : data loader dictionary\n",
    "                Containing the training volumes as the image and the training masks as the label\n",
    "           \n",
    "          \"\"\"\n",
    "        \n",
    "        train_loader = monai.data.DataLoader(\n",
    "        self.train_ds,\n",
    "        batch_size=self.batch_size,\n",
    "        num_workers=self.num_workers,\n",
    "        pin_memory=self.pin_memory,\n",
    "        )\n",
    "\n",
    "        return train_loader\n",
    "    \n",
    "    def get_testing_data(self):\n",
    "        r\"\"\"get_testing_data\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            None\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            test_loader : data loader dictionary\n",
    "                Containing the testing volumes as the image and the testing masks as the label\n",
    "           \n",
    "          \"\"\"\n",
    "        \n",
    "        test_loader = monai.data.DataLoader(\n",
    "        self.test_ds,\n",
    "        batch_size=self.batch_size,\n",
    "        num_workers=self.num_workers,\n",
    "        pin_memory=self.pin_memory,\n",
    "        )\n",
    "\n",
    "        return test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18b99e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MSD = DataLoader(\"MSD\", 5, num_workers=0, pin_memory=False , test_size=0.0, Transform = True, Keys=(\"image\", \"label\"),size=[500, 500, 30])\n",
    "# MSD_train = MSD.get_training_data()\n",
    "# for x in MSD_train:\n",
    "#     print(f\"label shape:{x['label'].shape}\")\n",
    "#     print(f\"image shape:{x['image'].shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataload=DataLoader(\"Barbary\"], 1 num_workers=0, pin_memory=False , test_size=0.15, Transform = False,\n",
    "#                  Keys=(\"image\", \"label\"),size=[500, 500, 30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
