{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e488cca034f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;31m# torch package for vision related things\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m  \u001b[1;31m# Parameterless functions, like (some) activation functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdatasets\u001b[0m  \u001b[1;31m# Standard datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransforms\u001b[0m  \u001b[1;31m# Transformations we can perform on our dataset for augmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;31m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mtensordot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36m_overload\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_overload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m     \u001b[0m_check_overload_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    770\u001b[0m     \u001b[0mqual_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_qualified_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_overloaded_fns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36m_check_overload_body\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_overload_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m         \u001b[0mparsed_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m         \u001b[1;31m# Parsing the function definition can raise an OSError if source is unavailable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\_sources.py\u001b[0m in \u001b[0;36mparse_def\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mparse_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0msourcelines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_lineno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_source_lines_and_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mErrorReport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[0msourcelines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_source_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msourcelines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msourcelines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\_sources.py\u001b[0m in \u001b[0;36mget_source_lines_and_file\u001b[1;34m(obj, error_msg)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsourcefile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0msourcelines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_lineno\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsourcelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         msg = (f\"Can't get source for {obj}. TorchScript requires source access in \"\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetsourcelines\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    965\u001b[0m     raised if the source code cannot be retrieved.\"\"\"\n\u001b[0;32m    966\u001b[0m     \u001b[0mobject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m     \u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mistraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    792\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\linecache.py\u001b[0m in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdatecache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mMemoryError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mclearcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\linecache.py\u001b[0m in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m             \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\tokenize.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[0mdetect_encoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \"\"\"\n\u001b[1;32m--> 392\u001b[1;33m     \u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_encoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision # torch package for vision related things\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn  # All neural network modules\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import os \n",
    "# Gives easier dataset managment by creating mini batches etc.\n",
    "from tqdm import tqdm  # For nice progress bar!\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nibabel.testing import data_path\n",
    "import os\n",
    "import nibabel as nib\n",
    "import cv2 as cv\n",
    "from nibabel.testing import data_path\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from monai.transforms import LoadImageD\n",
    "from monai.transforms import \\\n",
    "    LoadImageD, EnsureChannelFirstD, AddChannelD, ScaleIntensityD, ToTensorD, Compose,NormalizeIntensityD, \\\n",
    "    AsDiscreteD, SpacingD, OrientationD, ResizeD, RandSpatialCropd, Spacingd,RandFlipd, RandScaleIntensityd,RandShiftIntensityd, \\\n",
    "    RandSpatialCropd, RandRotated\n",
    "import monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-145d1c94ec9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmonai\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLoadImageD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mimport\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mLoadImageD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEnsureChannelFirstD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAddChannelD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mScaleIntensityD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mToTensorD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCompose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNormalizeIntensityD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mAsDiscreteD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpacingD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOrientationD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResizeD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandSpatialCropd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpacingd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRandFlipd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandScaleIntensityd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRandShiftIntensityd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\monai\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m     )\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_submodules\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# handlers_* have some external decorators the users may not have installed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\monai\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0maliases\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0malias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresolve_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMethodReplacer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRestartGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdeprecate_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDeprecatedError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeprecated_arg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mevenly_divisible_all_gather\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_dist_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_list_all_gather\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m from .enums import (\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\monai\\utils\\deprecate_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmonai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversion_leq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\monai\\utils\\module.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCollection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# bundle config system flags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mraise\u001b[0m  \u001b[1;31m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Base'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[0m__all__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import monai\n",
    "from monai.transforms import LoadImageD\n",
    "from monai.transforms import \\\n",
    "    LoadImageD, EnsureChannelFirstD, AddChannelD, ScaleIntensityD, ToTensorD, Compose,NormalizeIntensityD, \\\n",
    "    AsDiscreteD, SpacingD, OrientationD, ResizeD, RandSpatialCropd, Spacingd,RandFlipd, RandScaleIntensityd,RandShiftIntensityd, \\\n",
    "    RandSpatialCropd, RandRotated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize global variables \n",
    "\n",
    "roi_size=[500, 500, 30]\n",
    "# Paths = {\"Barbary\":\"C:/dataset\", }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS=(\"image\", \"label\")\n",
    "\n",
    "class preprocessing():\n",
    "    def __init__(self, KEYS=(\"image\", \"label\"), size=[500, 500, 30]):\n",
    "        r\"\"\"A Class that preprocesses data\n",
    "            __init__\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            KEYS : Dictionary labels for image and mask\n",
    "\n",
    "            size : 3d array of the wanted volume size \n",
    "                The type above can either refer to an actual Python type\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            No returns\n",
    "\n",
    "          \"\"\"\n",
    "        self.transform = Compose([\n",
    "            EnsureChannelFirstD(KEYS),\n",
    "#             AddChannelD(\"label\"), #assumes label is not rgb - will need to manually implement a class for multiple segments\n",
    "            OrientationD(KEYS, axcodes='LAS'), #preferred by radiologists\n",
    "            SpacingD(KEYS, pixdim=(1., 1., 1.), mode=('bilinear', 'nearest')),\n",
    "            ResizeD(KEYS, size , mode=('trilinear', 'nearest')),\n",
    "            RandFlipd(KEYS, prob=0.5, spatial_axis=1),\n",
    "            RandRotated(KEYS, range_x=0.1, range_y=0.1, range_z=0.1, prob=0.5, keep_size=True),\n",
    "            RandScaleIntensityd(keys=\"image\", factors=0.1, prob=0.5),\n",
    "            RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=0.5),\n",
    "            NormalizeIntensityD(KEYS, channel_wise=True), #normalize intensity to have mean = 0 and std = 1.\n",
    "            ToTensorD(KEYS),\n",
    "        ])\n",
    "    def __call__(self,data_dict):\n",
    "        r\"\"\"__call__\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            data_dict : Dictionary of paths for images and masks\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            \n",
    "            data_dict : Dictionary\n",
    "                the dictionary containing data after applying transformations.\n",
    "           \n",
    "          \"\"\"\n",
    "        data_dict = self.transform(data_dict)\n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calling preprocessing\n",
    "\n",
    "\n",
    "# ## load \n",
    "# dict_loader = LoadImageD(keys=(\"image\", \"label\"))\n",
    "# data_dict = dict_loader({\"image\": 'D:/GP/MSD/Path/hepaticvessel_051.nii' ,\n",
    "#                          \"label\": 'D:/GP/MSD/Path/hepaticvessel_051.nii'})\n",
    "# # ## plot\n",
    "# print(f\"image shape: {data_dict['image'].shape}, \\nlabel shape: {data_dict['label'].shape}\")\n",
    "# print(f\"mean is : { np.mean(data_dict['image'],dtype=np.float64) } \")\n",
    "# print(f\"std is : { np.std(data_dict['image'],dtype=np.float64)}\")\n",
    "    \n",
    "# # ##preprocess##    \n",
    "\n",
    "# preprocess = preprocessing(KEYS, roi_size)\n",
    "# data_dict_processed = preprocess(data_dict)\n",
    "\n",
    "# print(\"*********\")\n",
    "# print(f\"tansformed image shape: {data_dict_processed['image'].shape}, \\ntransformed label shape: {data_dict_processed['label'].shape}\")\n",
    "# print(f\"mean is: {np.mean(data_dict_processed['image'],dtype=np.float64)} \")\n",
    "# print(f\"std is : {np.std(data_dict_processed['image'],dtype=np.float64)}\")\n",
    "\n",
    "\n",
    "# f, ax = plt.subplots(1,2)\n",
    "\n",
    "# ax[0].imshow(data_dict[\"image\"][:,:,29])\n",
    "# ax[0].title.set_text('Original')\n",
    "\n",
    "# ax[1].imshow(data_dict_processed[\"image\"][0,:,:,29])\n",
    "# ax[1].title.set_text('Transformed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomData(Dataset):\n",
    "    def __init__(self, volume_dir, mask_dir, volumeNames, maskNames, KEYS=(\"image\", \"label\") ,roi_size=[500, 500, 30], \n",
    "                 transform = False):\n",
    "       \n",
    "        r\"\"\"__init__\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            volume_dir : string\n",
    "                directory for all the volumes.\n",
    "\n",
    "            volumeNames : Arr \n",
    "                Array of names inside the volume directory.\n",
    "            \n",
    "            mask_dir : string\n",
    "                directory for all the masks\n",
    "\n",
    "            maskNames : string \n",
    "                Array of names inside the mask directorymask.\n",
    "            \n",
    "            KEYS : Dictionary labels for image and mask.\n",
    "\n",
    "            roi_size : 3d array of the wanted volume size \n",
    "                The type above can either refer to an actual Python type.\n",
    "                \n",
    "            transform: boolean\n",
    "                 Set true if you want to preprocess the data.\n",
    "                 \n",
    "            Returns\n",
    "            -------\n",
    "            No returns\n",
    "            \n",
    "        \"\"\"\n",
    " \n",
    "        \n",
    "        self.volume_dir = volume_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.volumeNames = volumeNames\n",
    "        self.maskNames=maskNames\n",
    "        self.keys = KEYS\n",
    "\n",
    "        #transforms from monai transform lib \n",
    "        self.transform = transform\n",
    "        self.preprocess = preprocessing(KEYS, roi_size)\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        r\"\"\"__len__\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            no params \n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            \n",
    "            data length : int\n",
    "                Length of the whole dataset\n",
    "           \n",
    "          \"\"\"\n",
    "        return len(self.volumeNames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        r\"\"\"__getitem__\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            index : int \n",
    "                index of the required volume and mask\n",
    "            Returns\n",
    "            -------\n",
    "            \n",
    "            data_dict : dictionary\n",
    "                Containing the volume as the image and the mask as the label\n",
    "           \n",
    "          \"\"\"\n",
    "        \n",
    "               \n",
    "        volume_path = os.path.join(self.volume_dir, self.volumeNames[index])\n",
    "        mask_path = os.path.join(self.mask_dir, self.maskNames[index])\n",
    "         \n",
    "        dict_loader = LoadImageD(keys=self.keys)\n",
    "        data_dict = dict_loader({self.keys[0]: volume_path ,\n",
    "                                 self.keys[1]: mask_path})\n",
    "        if self.transform == True:\n",
    "            data_dict = self.preprocess(data_dict) \n",
    "        \n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, Paths,dataset_name, batch_size, num_workers=0, pin_memory=False , test_size=0.15, Transform = False,\n",
    "                 Keys=(\"image\", \"label\"),size=[500, 500, 30]):\n",
    "        \n",
    "        r\"\"\"__init__\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            dataset_name: string\n",
    "                name of the dataset to be loaded eg \"MSD\" or \"MED_seg\"\n",
    "                \n",
    "            batch_size: int\n",
    "                size of batches to be returned    \n",
    "            \n",
    "            test_size : float\n",
    "                proportion of the test size \n",
    "                \n",
    "            transform: boolean\n",
    "                 Set true if you want to preprocess the data.\n",
    "                 \n",
    "            volumeNames : Arr \n",
    "                Array of names inside the volume directory.\n",
    "            \n",
    "            Keys : Dictionary labels for image and mask.\n",
    "\n",
    "            size : 3d array of the wanted volume size \n",
    "                The type above can either refer to an actual Python type.\n",
    "                \n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            No returns\n",
    "            \n",
    "            Other Parameters\n",
    "            ----------------\n",
    "             num_workers : int, optional\n",
    "                set by default to 0\n",
    "            \n",
    "             pin_memory : boolean, optional\n",
    "                set by default to False\n",
    "\n",
    "          \"\"\"\n",
    "        \n",
    "        print(Paths[dataset_name])\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "        \n",
    "        self.volume_dir = os.path.join(Paths[dataset_name], \"Path\")\n",
    "        self.mask_dir = os.path.join(Paths[dataset_name], \"Path2\")\n",
    "       \n",
    "        self.volumeNames = os.listdir(self.volume_dir)\n",
    "        self.maskNames=os.listdir(self.mask_dir)\n",
    "        \n",
    "        test_size = int(test_size * len(self.volumeNames))\n",
    "        train_size = len(self.volumeNames)-test_size\n",
    "        \n",
    "        self.train_volumeNames, self.test_volumeNames = torch.utils.data.random_split(self.volumeNames, [train_size, test_size])\n",
    "        self.train_maskNames, self.test_maskNames = torch.utils.data.random_split(self.maskNames, [train_size, test_size])\n",
    "        \n",
    "        \n",
    "        self.train_ds = CustomData(\n",
    "        volume_dir=self.volume_dir,\n",
    "        mask_dir=self.mask_dir,\n",
    "        volumeNames =  self.train_volumeNames, \n",
    "        maskNames =  self.train_maskNames,\n",
    "        transform=Transform,\n",
    "        KEYS=Keys,\n",
    "        roi_size = size\n",
    "        )\n",
    "        \n",
    "        self.test_ds = CustomData(\n",
    "        volume_dir=self.volume_dir,\n",
    "        mask_dir=self.mask_dir,\n",
    "        volumeNames =  self.test_volumeNames, \n",
    "        maskNames =  self.test_maskNames,\n",
    "        transform=Transform,\n",
    "        KEYS=Keys,\n",
    "        roi_size = size\n",
    "        )\n",
    "        \n",
    "    def get_training_data(self):\n",
    "        \n",
    "        r\"\"\"get_training_data\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            None\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            train_loader : data loader dictionary\n",
    "                Containing the training volumes as the image and the training masks as the label\n",
    "           \n",
    "          \"\"\"\n",
    "        \n",
    "        train_loader = monai.data.DataLoader(\n",
    "        self.train_ds,\n",
    "        batch_size=self.batch_size,\n",
    "        num_workers=self.num_workers,\n",
    "        pin_memory=self.pin_memory,\n",
    "        )\n",
    "\n",
    "        return train_loader\n",
    "    \n",
    "    def get_testing_data(self):\n",
    "        r\"\"\"get_testing_data\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            None\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            test_loader : data loader dictionary\n",
    "                Containing the testing volumes as the image and the testing masks as the label\n",
    "           \n",
    "          \"\"\"\n",
    "        \n",
    "        test_loader = monai.data.DataLoader(\n",
    "        self.test_ds,\n",
    "        batch_size=self.batch_size,\n",
    "        num_workers=self.num_workers,\n",
    "        pin_memory=self.pin_memory,\n",
    "        )\n",
    "\n",
    "        return test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MSD = DataLoader(\"MSD\", 5, num_workers=0, pin_memory=False , test_size=0.0, Transform = True, Keys=(\"image\", \"label\"),size=[500, 500, 30])\n",
    "# MSD_train = MSD.get_training_data()\n",
    "# for x in MSD_train:\n",
    "#     print(f\"label shape:{x['label'].shape}\")\n",
    "#     print(f\"image shape:{x['image'].shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataload=DataLoader(\"Barbary\"], 1 num_workers=0, pin_memory=False , test_size=0.15, Transform = False,\n",
    "#                  Keys=(\"image\", \"label\"),size=[500, 500, 30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
