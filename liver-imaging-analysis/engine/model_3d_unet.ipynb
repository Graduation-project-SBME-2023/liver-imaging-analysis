{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRpdxvm8ij5G"
      },
      "source": [
        "fe 2wel box da ba5od el tensor el tale3 mn el data loader bta3ko fa 2nto 2ms7oh w 2b3to lel model el 3ltol zy 2a5er box "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k108vGBNEzeY",
        "outputId": "ee3c970c-0182-4556-e338-b0b283f01e7c"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from torch import nn\n",
        "import torch.nn as nn\n",
        "from functools import partial\n",
        "import torch\n",
        "from torch import nn as nn\n",
        "from torch.nn import functional as F\n",
        "import importlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMNFGPdEr_yP"
      },
      "source": [
        "b8yar el shape 3shan el conv3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CxEj2XOruo9",
        "outputId": "d7c738f7-a50d-477e-b6cb-58c3c13d6fb2"
      },
      "outputs": [],
      "source": [
        "# inputs=inputs.expand(1,inputs.shape[0],inputs.shape[1],inputs.shape[2],inputs.shape[3])\n",
        "# inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uB9P2NbWTjxb"
      },
      "outputs": [],
      "source": [
        "class Abstract3DUNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Base class for standard and residual UNet.\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output segmentation masks;\n",
        "            Note that that the of out_channels might correspond to either\n",
        "            different semantic classes or to different binary segmentation mask.\n",
        "            It's up to the user of the class to interpret the out_channels and\n",
        "            use the proper loss criterion during training (i.e. CrossEntropyLoss (multi-class)\n",
        "            or BCEWithLogitsLoss (two-class) respectively)\n",
        "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
        "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
        "        final_sigmoid (bool): if True apply element-wise nn.Sigmoid after the\n",
        "            final 1x1 convolution, otherwise apply nn.Softmax. MUST be True if nn.BCELoss (two-class) is used\n",
        "            to train the model. MUST be False if nn.CrossEntropyLoss (multi-class) is used to train the model.\n",
        "        basic_module: basic model for the encoder/decoder (DoubleConv, ExtResNetBlock, ....)\n",
        "        layer_order (string): determines the order of layers\n",
        "            in `SingleConv` module. e.g. 'crg' stands for Conv3d+ReLU+GroupNorm3d.\n",
        "            See `SingleConv` for more info\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        num_levels (int): number of levels in the encoder/decoder path (applied only if f_maps is an int)\n",
        "        is_segmentation (bool): if True (semantic segmentation problem) Sigmoid/Softmax normalization is applied\n",
        "            after the final convolution; if False (regression problem) the normalization layer is skipped at the end\n",
        "        conv_kernel_size (int or tuple): size of the convolving kernel in the basic_module\n",
        "        pool_kernel_size (int or tuple): the size of the window\n",
        "        conv_padding (int or tuple): add zero-padding added to all three sides of the input\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, final_sigmoid, basic_module, f_maps=64, layer_order='gcr',\n",
        "                 num_groups=8, num_levels=4, is_segmentation=True, conv_kernel_size=3, pool_kernel_size=2,\n",
        "                 conv_padding=1, **kwargs):\n",
        "        super(Abstract3DUNet, self).__init__()\n",
        "\n",
        "        if isinstance(f_maps, int):\n",
        "            f_maps = number_of_features_per_level(f_maps, num_levels=num_levels)\n",
        "\n",
        "        assert isinstance(f_maps, list) or isinstance(f_maps, tuple)\n",
        "        assert len(f_maps) > 1, \"Required at least 2 levels in the U-Net\"\n",
        "\n",
        "        # create encoder path\n",
        "        self.encoders = create_encoders(in_channels, f_maps, basic_module, conv_kernel_size, conv_padding, layer_order,\n",
        "                                        num_groups, pool_kernel_size)\n",
        "\n",
        "        # create decoder path\n",
        "        self.decoders = create_decoders(f_maps, basic_module, conv_kernel_size, conv_padding, layer_order, num_groups,\n",
        "                                        upsample=True)\n",
        "\n",
        "        # in the last layer a 1Ã—1 convolution reduces the number of output\n",
        "        # channels to the number of labels\n",
        "        self.final_conv = nn.Conv3d(f_maps[0], out_channels, 1)\n",
        "\n",
        "        if is_segmentation:\n",
        "            # semantic segmentation problem\n",
        "            if final_sigmoid:\n",
        "                self.final_activation = nn.Sigmoid()\n",
        "            else:\n",
        "                self.final_activation = nn.Softmax(dim=1)\n",
        "        else:\n",
        "            # regression problem\n",
        "            self.final_activation = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoder part\n",
        "        encoders_features = []\n",
        "        for encoder in self.encoders:\n",
        "            x = encoder(x)\n",
        "            # reverse the encoder outputs to be aligned with the decoder\n",
        "            encoders_features.insert(0, x)\n",
        "\n",
        "        # remove the last encoder's output from the list\n",
        "        # !!remember: it's the 1st in the list\n",
        "        encoders_features = encoders_features[1:]\n",
        "\n",
        "        # decoder part\n",
        "        for decoder, encoder_features in zip(self.decoders, encoders_features):\n",
        "            # pass the output from the corresponding encoder and the output\n",
        "            # of the previous decoder\n",
        "            x = decoder(encoder_features, x)\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "\n",
        "        # apply final_activation (i.e. Sigmoid or Softmax) only during prediction. During training the network outputs logits\n",
        "        if not self.training and self.final_activation is not None: #### there are loss funcs that need the output without applying to the activation function\n",
        "            x = self.final_activation(x)   \n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class UNet3D(Abstract3DUNet):\n",
        "    \"\"\"\n",
        "    3DUnet model from\n",
        "    `\"3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation\"\n",
        "        <https://arxiv.org/pdf/1606.06650.pdf>`.\n",
        "    Uses `DoubleConv` as a basic_module and nearest neighbor upsampling in the decoder\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, final_sigmoid=True, f_maps=64, layer_order='gcr',\n",
        "                 num_groups=8, num_levels=4, is_segmentation=True, conv_padding=1, **kwargs):\n",
        "        super(UNet3D, self).__init__(in_channels=in_channels,\n",
        "                                     out_channels=out_channels,\n",
        "                                     final_sigmoid=final_sigmoid,\n",
        "                                     basic_module=DoubleConv,\n",
        "                                     f_maps=f_maps,\n",
        "                                     layer_order=layer_order,\n",
        "                                     num_groups=num_groups,\n",
        "                                     num_levels=num_levels,\n",
        "                                     is_segmentation=is_segmentation,\n",
        "                                     conv_padding=conv_padding,\n",
        "                                     **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "remnMnDBZSV4"
      },
      "outputs": [],
      "source": [
        "def number_of_features_per_level(init_channel_number, num_levels):\n",
        "    return [init_channel_number * 2 ** k for k in range(num_levels)]\n",
        "\n",
        "\n",
        "def conv3d(in_channels, out_channels, kernel_size, bias, padding):\n",
        "    return nn.Conv3d(in_channels, out_channels, kernel_size, padding=padding, bias=bias)\n",
        "\n",
        "\n",
        "def create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding):\n",
        "    \"\"\"\n",
        "    Create a list of modules with together constitute a single conv layer with non-linearity\n",
        "    and optional batchnorm/groupnorm.\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output channels\n",
        "        kernel_size(int or tuple): size of the convolving kernel\n",
        "        order (string): order of things, e.g.\n",
        "            'cr' -> conv + ReLU\n",
        "            'gcr' -> groupnorm + conv + ReLU\n",
        "            'cl' -> conv + LeakyReLU\n",
        "            'ce' -> conv + ELU\n",
        "            'bcr' -> batchnorm + conv + ReLU\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
        "    Return:\n",
        "        list of tuple (name, module)\n",
        "    \"\"\"\n",
        "    assert 'c' in order, \"Conv layer MUST be present\"\n",
        "    assert order[0] not in 'rle', 'Non-linearity cannot be the first operation in the layer'\n",
        "\n",
        "    modules = []\n",
        "    for i, char in enumerate(order):\n",
        "        if char == 'r':\n",
        "            modules.append(('ReLU', nn.ReLU(inplace=True)))\n",
        "        elif char == 'l':\n",
        "            modules.append(('LeakyReLU', nn.LeakyReLU(inplace=True)))\n",
        "        elif char == 'e':\n",
        "            modules.append(('ELU', nn.ELU(inplace=True)))\n",
        "        elif char == 'c':\n",
        "            # add learnable bias only in the absence of batchnorm/groupnorm\n",
        "            bias = not ('g' in order or 'b' in order)\n",
        "            modules.append(('conv', conv3d(in_channels, out_channels, kernel_size, bias, padding=padding)))\n",
        "        elif char == 'g':\n",
        "            is_before_conv = i < order.index('c')\n",
        "            if is_before_conv:\n",
        "                num_channels = in_channels\n",
        "            else:\n",
        "                num_channels = out_channels\n",
        "\n",
        "            # use only one group if the given number of groups is greater than the number of channels\n",
        "            if num_channels < num_groups:\n",
        "                num_groups = 1\n",
        "\n",
        "            assert num_channels % num_groups == 0, f'Expected number of channels in input to be divisible by num_groups. num_channels={num_channels}, num_groups={num_groups}'\n",
        "            modules.append(('groupnorm', nn.GroupNorm(num_groups=num_groups, num_channels=num_channels)))\n",
        "        elif char == 'b':\n",
        "            is_before_conv = i < order.index('c')\n",
        "            if is_before_conv:\n",
        "                modules.append(('batchnorm', nn.BatchNorm3d(in_channels)))\n",
        "            else:\n",
        "                modules.append(('batchnorm', nn.BatchNorm3d(out_channels)))\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported layer type '{char}'. MUST be one of ['b', 'g', 'r', 'l', 'e', 'c']\")\n",
        "\n",
        "    return modules\n",
        "\n",
        "\n",
        "class SingleConv(nn.Sequential):\n",
        "    \"\"\"\n",
        "    Basic convolutional module consisting of a Conv3d, non-linearity and optional batchnorm/groupnorm. The order\n",
        "    of operations can be specified via the `order` parameter\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output channels\n",
        "        kernel_size (int or tuple): size of the convolving kernel\n",
        "        order (string): determines the order of layers, e.g.\n",
        "            'cr' -> conv + ReLU\n",
        "            'crg' -> conv + ReLU + groupnorm\n",
        "            'cl' -> conv + LeakyReLU\n",
        "            'ce' -> conv + ELU\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        padding (int or tuple):\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
        "        super(SingleConv, self).__init__()\n",
        "\n",
        "        for name, module in create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding=padding):\n",
        "            self.add_module(name, module)\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Sequential):\n",
        "    \"\"\"\n",
        "    A module consisting of two consecutive convolution layers (e.g. BatchNorm3d+ReLU+Conv3d).\n",
        "    We use (Conv3d+ReLU+GroupNorm3d) by default.\n",
        "    This can be changed however by providing the 'order' argument, e.g. in order\n",
        "    to change to Conv3d+BatchNorm3d+ELU use order='cbe'.\n",
        "    Use padded convolutions to make sure that the output (H_out, W_out) is the same\n",
        "    as (H_in, W_in), so that you don't have to crop in the decoder path.\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output channels\n",
        "        encoder (bool): if True we're in the encoder path, otherwise we're in the decoder\n",
        "        kernel_size (int or tuple): size of the convolving kernel\n",
        "        order (string): determines the order of layers, e.g.\n",
        "            'cr' -> conv + ReLU\n",
        "            'crg' -> conv + ReLU + groupnorm\n",
        "            'cl' -> conv + LeakyReLU\n",
        "            'ce' -> conv + ELU\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, encoder, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        if encoder:\n",
        "            # we're in the encoder path\n",
        "            conv1_in_channels = in_channels\n",
        "            conv1_out_channels = out_channels // 2\n",
        "            if conv1_out_channels < in_channels:\n",
        "                conv1_out_channels = in_channels\n",
        "            conv2_in_channels, conv2_out_channels = conv1_out_channels, out_channels\n",
        "        else:\n",
        "            # we're in the decoder path, decrease the number of channels in the 1st convolution\n",
        "            conv1_in_channels, conv1_out_channels = in_channels, out_channels\n",
        "            conv2_in_channels, conv2_out_channels = out_channels, out_channels\n",
        "\n",
        "        # conv1\n",
        "        self.add_module('SingleConv1',\n",
        "                        SingleConv(conv1_in_channels, conv1_out_channels, kernel_size, order, num_groups,\n",
        "                                   padding=padding))\n",
        "        # conv2\n",
        "        self.add_module('SingleConv2',\n",
        "                        SingleConv(conv2_in_channels, conv2_out_channels, kernel_size, order, num_groups,\n",
        "                                   padding=padding))\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A single module from the encoder path consisting of the optional max\n",
        "    pooling layer (one may specify the MaxPool kernel_size to be different\n",
        "    than the standard (2,2,2), e.g. if the volumetric data is anisotropic\n",
        "    (make sure to use complementary scale_factor in the decoder path) followed by\n",
        "    a DoubleConv module.\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output channels\n",
        "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
        "        apply_pooling (bool): if True use MaxPool3d before DoubleConv\n",
        "        pool_kernel_size (int or tuple): the size of the window\n",
        "        pool_type (str): pooling layer: 'max' or 'avg'\n",
        "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
        "        conv_layer_order (string): determines the order of layers\n",
        "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, apply_pooling=True,\n",
        "                 pool_kernel_size=2, pool_type='max', basic_module=DoubleConv, conv_layer_order='gcr',\n",
        "                 num_groups=8, padding=1):\n",
        "        super(Encoder, self).__init__()\n",
        "        assert pool_type in ['max', 'avg']\n",
        "        if apply_pooling:\n",
        "            if pool_type == 'max':\n",
        "                self.pooling = nn.MaxPool3d(kernel_size=pool_kernel_size)\n",
        "            else:\n",
        "                self.pooling = nn.AvgPool3d(kernel_size=pool_kernel_size)\n",
        "        else:\n",
        "            self.pooling = None\n",
        "\n",
        "        self.basic_module = basic_module(in_channels, out_channels,\n",
        "                                         encoder=True,\n",
        "                                         kernel_size=conv_kernel_size,\n",
        "                                         order=conv_layer_order,\n",
        "                                         num_groups=num_groups,\n",
        "                                         padding=padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.pooling is not None:\n",
        "            x = self.pooling(x)\n",
        "        x = self.basic_module(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A single module for decoder path consisting of the upsampling layer\n",
        "    (either learned ConvTranspose3d or nearest neighbor interpolation) followed by a basic module (DoubleConv or ExtResNetBlock).\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output channels\n",
        "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
        "        scale_factor (tuple): used as the multiplier for the image H/W/D in\n",
        "            case of nn.Upsample or as stride in case of ConvTranspose3d, must reverse the MaxPool3d operation\n",
        "            from the corresponding encoder\n",
        "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
        "        conv_layer_order (string): determines the order of layers\n",
        "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
        "        upsample (boole): should the input be upsampled\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, scale_factor=(2, 2, 2), basic_module=DoubleConv,\n",
        "                 conv_layer_order='gcr', num_groups=8, mode='nearest', padding=1, upsample=True):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        if upsample:\n",
        "          # if DoubleConv is the basic_module use interpolation for upsampling and concatenation joining\n",
        "          self.upsampling = InterpolateUpsampling(mode=mode)    ##############search##############                                       \n",
        "          # concat joining\n",
        "          self.joining = partial(self._joining, concat=True)    ##############search##############  \n",
        "            \n",
        "        else:\n",
        "            # no upsampling\n",
        "            self.upsampling = NoUpsampling()\n",
        "            # concat joining\n",
        "            self.joining = partial(self._joining, concat=True)\n",
        "\n",
        "        self.basic_module = basic_module(in_channels, out_channels,\n",
        "                                         encoder=False,\n",
        "                                         kernel_size=conv_kernel_size,\n",
        "                                         order=conv_layer_order,\n",
        "                                         num_groups=num_groups,\n",
        "                                         padding=padding)\n",
        "\n",
        "    def forward(self, encoder_features, x):\n",
        "        x = self.upsampling(encoder_features=encoder_features, x=x)\n",
        "        x = self.joining(encoder_features, x)\n",
        "        x = self.basic_module(x)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def _joining(encoder_features, x, concat):\n",
        "        if concat:\n",
        "            return torch.cat((encoder_features, x), dim=1)\n",
        "        else:\n",
        "            return encoder_features + x #################search##########\n",
        "\n",
        "\n",
        "def create_encoders(in_channels, f_maps, basic_module, conv_kernel_size, conv_padding, layer_order, num_groups,\n",
        "                    pool_kernel_size):\n",
        "    # create encoder path consisting of Encoder modules. Depth of the encoder is equal to `len(f_maps)`\n",
        "    encoders = []\n",
        "    for i, out_feature_num in enumerate(f_maps):\n",
        "        if i == 0:\n",
        "            encoder = Encoder(in_channels, out_feature_num,\n",
        "                              apply_pooling=False,  # skip pooling in the firs encoder\n",
        "                              basic_module=basic_module,\n",
        "                              conv_layer_order=layer_order,\n",
        "                              conv_kernel_size=conv_kernel_size,\n",
        "                              num_groups=num_groups,\n",
        "                              padding=conv_padding)\n",
        "        else:\n",
        "            #adapt for anisotropy in the data, i.e. use proper pooling kernel to make the data isotropic after 1-2 pooling operations\n",
        "            encoder = Encoder(f_maps[i - 1], out_feature_num,\n",
        "                              basic_module=basic_module,\n",
        "                              conv_layer_order=layer_order,\n",
        "                              conv_kernel_size=conv_kernel_size,\n",
        "                              num_groups=num_groups,\n",
        "                              pool_kernel_size=pool_kernel_size,\n",
        "                              padding=conv_padding)\n",
        "\n",
        "        encoders.append(encoder)\n",
        "\n",
        "    return nn.ModuleList(encoders)\n",
        "\n",
        "\n",
        "def create_decoders(f_maps, basic_module, conv_kernel_size, conv_padding, layer_order, num_groups, upsample):\n",
        "    # create decoder path consisting of the Decoder modules. The length of the decoder list is equal to `len(f_maps) - 1`\n",
        "    decoders = []\n",
        "    reversed_f_maps = list(reversed(f_maps))\n",
        "    for i in range(len(reversed_f_maps) - 1):\n",
        "        in_feature_num = reversed_f_maps[i] + reversed_f_maps[i + 1]\n",
        "        out_feature_num = reversed_f_maps[i + 1]\n",
        "\n",
        "        # if non-standard pooling was used, make sure to use correct striding for transpose conv\n",
        "        # currently strides with a constant stride: (2, 2, 2)\n",
        "\n",
        "        _upsample = True\n",
        "        if i == 0:\n",
        "            # upsampling can be skipped only for the 1st decoder, afterwards it should always be present\n",
        "            _upsample = upsample\n",
        "\n",
        "        decoder = Decoder(in_feature_num, out_feature_num,\n",
        "                          basic_module=basic_module,\n",
        "                          conv_layer_order=layer_order,\n",
        "                          conv_kernel_size=conv_kernel_size,\n",
        "                          num_groups=num_groups,\n",
        "                          padding=conv_padding,\n",
        "                          upsample=_upsample)\n",
        "        decoders.append(decoder)\n",
        "    return nn.ModuleList(decoders)\n",
        "\n",
        "\n",
        "class AbstractUpsampling(nn.Module):\n",
        "    \"\"\"\n",
        "    Abstract class for upsampling. A given implementation should upsample a given 5D input tensor using either\n",
        "    interpolation or learned transposed convolution.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, upsample):\n",
        "        super(AbstractUpsampling, self).__init__()\n",
        "        self.upsample = upsample\n",
        "\n",
        "    def forward(self, encoder_features, x):\n",
        "        # get the spatial dimensions of the output given the encoder_features\n",
        "        output_size = encoder_features.size()[2:]\n",
        "        # upsample the input and return\n",
        "        return self.upsample(x, output_size)\n",
        "\n",
        "\n",
        "class InterpolateUpsampling(AbstractUpsampling):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        mode (str): algorithm used for upsampling:\n",
        "            'nearest' | 'linear' | 'bilinear' | 'trilinear' | 'area'. Default: 'nearest'\n",
        "            used only if transposed_conv is False\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mode='nearest'):\n",
        "        upsample = partial(self._interpolate, mode=mode)\n",
        "        super().__init__(upsample)\n",
        "\n",
        "    @staticmethod\n",
        "    def _interpolate(x, size, mode):\n",
        "        return F.interpolate(x, size=size, mode=mode)\n",
        "\n",
        "\n",
        "class NoUpsampling(AbstractUpsampling):\n",
        "    def __init__(self):\n",
        "        super().__init__(self._no_upsampling)\n",
        "\n",
        "    @staticmethod\n",
        "    def _no_upsampling(x, size):\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrC8uSGIxDrL"
      },
      "outputs": [],
      "source": [
        "# model=UNet3D(1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv6MDS5TLmZE",
        "outputId": "90e3920c-1d7f-4e16-b26f-c0d79b22fbab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[[ 8.4064e-02,  4.9873e-02, -2.5245e-03,  ...,  2.0261e-01,\n",
              "             9.3800e-02,  1.7125e-02],\n",
              "           [-3.4805e-02, -5.8838e-02, -1.0127e-01,  ...,  7.5786e-03,\n",
              "            -1.1944e-02, -8.3281e-02],\n",
              "           [ 5.3857e-02,  1.1755e-01,  1.1695e-01,  ...,  9.1161e-02,\n",
              "            -2.6503e-02, -6.4206e-02],\n",
              "           ...,\n",
              "           [-5.3717e-02,  1.5463e-01,  7.2715e-02,  ..., -2.9022e-03,\n",
              "            -4.3326e-02, -1.1313e-01],\n",
              "           [-5.1632e-02,  1.6279e-01,  5.7366e-02,  ..., -2.3073e-03,\n",
              "             4.5320e-02, -8.6647e-02],\n",
              "           [ 7.1621e-02,  1.5511e-01,  3.7057e-02,  ...,  2.6925e-02,\n",
              "             4.1854e-02, -7.9514e-02]],\n",
              "\n",
              "          [[ 1.1776e-01, -1.3283e-02, -2.0542e-02,  ...,  2.0099e-01,\n",
              "             4.0629e-02,  2.7289e-02],\n",
              "           [ 3.1396e-02, -8.3844e-02, -8.3332e-02,  ...,  4.5680e-02,\n",
              "             5.4483e-02,  2.5994e-03],\n",
              "           [ 5.7146e-02,  1.0046e-01,  2.2936e-01,  ...,  1.2052e-01,\n",
              "             2.6364e-02,  5.3804e-02],\n",
              "           ...,\n",
              "           [ 2.3664e-02,  1.3525e-01, -6.4836e-02,  ..., -1.4683e-01,\n",
              "            -3.4680e-05, -1.1551e-01],\n",
              "           [ 3.9181e-02,  8.7299e-02,  1.7879e-01,  ...,  8.1577e-02,\n",
              "            -5.0036e-02, -1.9230e-01],\n",
              "           [ 1.5287e-01,  2.2514e-01, -3.1712e-03,  ...,  9.5594e-02,\n",
              "             1.5732e-01, -1.1784e-01]],\n",
              "\n",
              "          [[ 7.3543e-02, -4.8148e-02, -1.7653e-02,  ...,  1.6135e-01,\n",
              "             4.3579e-02, -2.2429e-02],\n",
              "           [ 9.5881e-02, -6.4381e-02, -1.2920e-01,  ...,  5.1956e-02,\n",
              "             8.9374e-03, -6.2641e-02],\n",
              "           [ 1.2176e-01,  9.1316e-02,  1.7244e-01,  ..., -4.7657e-02,\n",
              "             1.1800e-01,  5.3317e-02],\n",
              "           ...,\n",
              "           [ 5.1839e-02,  9.9834e-02,  6.8066e-02,  ..., -1.5262e-01,\n",
              "            -4.2810e-02, -6.6088e-02],\n",
              "           [-6.9368e-05,  6.9743e-02,  1.7087e-01,  ...,  6.3762e-02,\n",
              "            -7.0700e-02, -2.7124e-01],\n",
              "           [ 1.2566e-01,  3.0482e-01,  7.3519e-03,  ...,  1.5236e-01,\n",
              "             1.6805e-01, -2.0344e-01]],\n",
              "\n",
              "          ...,\n",
              "\n",
              "          [[-3.3784e-02, -2.7001e-02, -8.5245e-02,  ...,  1.7810e-01,\n",
              "             1.2593e-01,  4.1434e-02],\n",
              "           [-7.5796e-02, -9.3676e-02, -3.3406e-01,  ...,  1.0679e-01,\n",
              "             9.2050e-02, -2.5949e-02],\n",
              "           [ 1.5508e-02,  1.9248e-01, -1.9675e-01,  ...,  1.3296e-01,\n",
              "             1.2060e-01,  1.1486e-01],\n",
              "           ...,\n",
              "           [-1.9716e-01,  8.5414e-02,  2.3835e-02,  ...,  9.0310e-02,\n",
              "             5.1874e-02,  2.8806e-02],\n",
              "           [-1.8997e-01, -2.2186e-01,  1.0470e-01,  ...,  6.3921e-02,\n",
              "            -8.4978e-03,  6.8688e-02],\n",
              "           [-1.1820e-01,  4.3467e-02,  6.0329e-02,  ...,  7.3676e-02,\n",
              "             4.9844e-02,  3.6846e-02]],\n",
              "\n",
              "          [[ 5.1644e-02,  4.6007e-03, -2.9812e-02,  ...,  5.3858e-02,\n",
              "             1.5744e-01,  9.7576e-02],\n",
              "           [ 1.5566e-02,  5.7666e-02, -6.4953e-02,  ...,  3.3518e-03,\n",
              "             8.6198e-02,  7.6475e-02],\n",
              "           [ 1.1857e-01,  1.6240e-01, -2.3133e-01,  ..., -3.3425e-02,\n",
              "             1.1124e-01, -3.1040e-03],\n",
              "           ...,\n",
              "           [-2.2892e-01, -2.0718e-03, -9.0867e-02,  ...,  1.2284e-01,\n",
              "             3.3772e-02,  1.3984e-01],\n",
              "           [-1.7337e-01, -2.9321e-01, -9.1254e-02,  ...,  5.8159e-03,\n",
              "             7.4446e-02,  1.1087e-01],\n",
              "           [-1.0623e-01, -6.8718e-02,  2.3024e-02,  ...,  1.1155e-01,\n",
              "             5.7678e-02, -4.4850e-02]],\n",
              "\n",
              "          [[ 1.8095e-02,  8.0437e-02,  2.9999e-02,  ...,  1.1982e-01,\n",
              "             2.3064e-01,  1.5501e-01],\n",
              "           [ 6.3639e-02,  1.6229e-01,  3.3843e-02,  ...,  1.4973e-01,\n",
              "             1.5168e-01,  4.6344e-02],\n",
              "           [-9.9975e-03,  6.8872e-02, -8.5139e-02,  ...,  1.3050e-01,\n",
              "             7.5009e-02,  2.6377e-02],\n",
              "           ...,\n",
              "           [ 1.8894e-02,  8.1734e-02,  3.1028e-02,  ...,  2.4604e-01,\n",
              "             2.2243e-01,  5.9476e-02],\n",
              "           [ 2.9408e-02, -8.0437e-02, -9.8072e-02,  ...,  4.0346e-02,\n",
              "             8.0501e-02, -1.7280e-02],\n",
              "           [ 1.1819e-01, -4.1220e-02, -2.8608e-02,  ...,  1.4368e-01,\n",
              "             3.1889e-02, -9.0841e-02]]]]], grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# x=model(inputs)\n",
        "# x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAcr1kczsC_b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
