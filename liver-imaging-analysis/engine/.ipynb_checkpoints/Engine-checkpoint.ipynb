{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\requests\\__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from DataLoader.ipynb\n",
      "importing Jupyter notebook from model_3d_unet.ipynb\n",
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "import DataLoader as dp\n",
    "import model_3d_unet as unet\n",
    "import loss_functions as losses\n",
    "import utils as utils\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL = False\n",
    "\n",
    "\n",
    "class Engine (nn.Module):\n",
    "    \n",
    "    \"\"\"\"\n",
    "        Class that implements the basic PyTorch methods for neural network\n",
    "        Neural Networks should inherit from this class\n",
    "        Methods:\n",
    "            LoadData: load and save the data to the data attribute\n",
    "                Args:   Paths: dictionary that includes dataset names and their respective directories\n",
    "                               directories should include two folders: \"Path1\" and \"Path2\" containing features and labels, respectively.\n",
    "                        dataset_name: string of the dataset name to be loaded from Paths\n",
    "                        transformation_flag: boolean that indicates if data preprocessing will occur or not. \n",
    "                                             False will ignore \"transformation\" arguement \n",
    "                        transformation: an array of the shape data will be transformed into. eg; [64,512,512]\n",
    "                        batchsize: the number of features to be loaded in each batch. Default: 1\n",
    "                        test_valid_split: a number between 0-1 that indicate the portion of dataset to be loaded to the validation set. Default: 0\n",
    "            DataStatus: Prints the shape and dtype of the first batch of the training set and testing set, if exists.\n",
    "            Compile: Stores the loss function, the optimizer, and the metrics to be used during fitting and evaluating\n",
    "                Args: loss: the loss function to be used, should be imported from loss_functions\n",
    "                      optimizer: the optimizer to be used, should be imported from torch.optim\n",
    "                      metrics: the metrics calculated for each batch per epoch during training, and for the whole data during evaluating\n",
    "                               expects and array of string of one or more of: 'loss', 'dice_score'. Default: ['loss']\n",
    "            CompileStatus: Prints the stored loss function, optimizer, and metrics.\n",
    "            Fit: train the model using the stored training set\n",
    "                Args: epochs: the number of iterations for fitting. Default: 1\n",
    "            Test: function the calculate metrics without updating weights\n",
    "                Args: dataloader: the dataset to evaluate on\n",
    "            Evaluate_train: function that evaluates the model on the stored training dataset by calling \"Test\" \n",
    "            Evaluate_test: function that evaluates the model on the stored testing dataset by calling \"Test\" \n",
    "            Predict: predict the label of the given input using the current weights\n",
    "                Args: XPath: path of the input feature. expects a nifti file.\n",
    "                returns: tensor of the predicted label\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        #self.Device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.Device= \"cpu\"\n",
    "        super(Engine,self).__init__()\n",
    "\n",
    "\n",
    "    def LoadData(self,Paths,dataset_name,transformation_flag,transformation,batchsize=1,test_valid_split=0):\n",
    "        self.transformation=transformation\n",
    "        self.expand_flag= not transformation_flag\n",
    "        self.train_dataloader=[]\n",
    "        self.test_dataloader=[]\n",
    "        DataLoader= dp.DataLoader(Paths,dataset_name,batchsize,0,False,test_valid_split,transformation_flag,dp.KEYS,transformation)\n",
    "        self.train_dataloader= DataLoader.get_training_data()\n",
    "        self.test_dataloader= DataLoader.get_testing_data()\n",
    "             \n",
    "\n",
    "    def DataStatus(self):\n",
    "        for Batch in self.train_dataloader:\n",
    "            print(f\"Batch Shape of Training Features: {Batch['image'].shape} {Batch['image'].dtype}\")\n",
    "            print(f\"Batch Shape of Training Labels: {Batch['label'].shape} {Batch['label'].dtype}\")\n",
    "            break\n",
    "        for Batch in self.test_dataloader:\n",
    "            print(f\"Batch Shape of Testing Features: {Batch['image'].shape} {Batch['image'].dtype}\")\n",
    "            print(f\"Batch Shape of Testing Labels: {Batch['label'].shape} {Batch['label'].dtype}\")\n",
    "            break\n",
    "\n",
    "\n",
    "    def Compile (self,loss,optimizer,metrics=['loss']):\n",
    "        self.Loss=loss\n",
    "        self.Optimizer=optimizer\n",
    "        self.Metrics=metrics\n",
    "\n",
    "\n",
    "    def CompileStatus (self):\n",
    "        print(f\"Loss= {self.Loss} \\n\")\n",
    "        print(f\"Optimizer= {self.Optimizer} \\n\")\n",
    "        print(f\"Metrics= {self.Metrics} \\n\")\n",
    "        \n",
    "\n",
    "    def Fit(self,epochs=1):\n",
    "        self.Epochs=epochs\n",
    "        for t in range(epochs):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            size = self.train_dataloader.__len__()\n",
    "            self.train()\n",
    "            for batch_num, batch in enumerate(self.train_dataloader):\n",
    "                X,y= batch['image'].to(self.Device),batch['label'].to(self.Device)\n",
    "                if (self.expand_flag):\n",
    "                    X=X.expand(1,X.shape[0],X.shape[1],X.shape[2],X.shape[3])\n",
    "                    y=y.expand(1,y.shape[0],y.shape[1],y.shape[2],y.shape[3])\n",
    "                pred = self(X)\n",
    "                loss = self.Loss(pred, y)\n",
    "                # Backpropagation\n",
    "                self.Optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.Optimizer.step()\n",
    "                #Print Progress\n",
    "                current= batch_num * len(X) +1\n",
    "                if 'loss' in self.Metrics:\n",
    "                    print(f\"loss: {loss.item():>7f}        [{current:>5d}/{size:>5d}]\")\n",
    "                if 'dice_score' in self.Metrics:\n",
    "                    print(f\"Dice Score: {(1-loss.item()):>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "                        # save model\n",
    "                checkpoint = {\n",
    "                    \"state_dict\": self.state_dict(),\n",
    "                    \"optimizer\":self.Optimizer.state_dict(),\n",
    "                }\n",
    "                \n",
    "                utils.save_checkpoint(checkpoint)\n",
    "                # if 'accuracy' in self.Metrics:\n",
    "                #     self.eval()\n",
    "                #     with torch.no_grad():\n",
    "                #             pred = self(X)\n",
    "                #     correct = int((pred.round()==y).sum())\n",
    "                #     correct /= math.prod(pred.shape)\n",
    "                #     print(f\"Accuracy: {(100*correct):>0.1f}%       [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "                    \n",
    "    def Test(self, dataloader):\n",
    "        num_batches = len(dataloader)\n",
    "        self.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                X,y= batch['image'].to(self.Device),batch['label'].to(self.Device)\n",
    "                if (self.expand_flag):\n",
    "                    X=X.expand(1,X.shape[0],X.shape[1],X.shape[2],X.shape[3])\n",
    "                    y=y.expand(1,y.shape[0],y.shape[1],y.shape[2],y.shape[3])\n",
    "                pred = self(X)\n",
    "                if 'loss' or 'dice_score' in self.Metrics:\n",
    "                    test_loss += self.Loss(pred, y).item()\n",
    "        test_loss /= num_batches\n",
    "        if 'loss' in self.Metrics:\n",
    "            print(f\"loss: {test_loss:>7f}\")\n",
    "        if 'dice_score' in self.Metrics:\n",
    "            print(f\"Dice Score: {(1-test_loss):>7f}\")\n",
    "\n",
    "\n",
    "    def Evaluate_train(self):\n",
    "        self.Test(self.train_dataloader)\n",
    "\n",
    "    def Evaluate_test(self):\n",
    "        self.Test(self.test_dataloader)\n",
    "        \n",
    "\n",
    "    def Predict(self,XPath):\n",
    "        dict_loader = dp.LoadImageD(keys=(\"image\", \"label\"))\n",
    "        data_dict = dict_loader({\"image\": XPath ,\"label\": XPath})\n",
    "        preprocess = dp.preprocessing((\"image\", \"label\"), self.transformation)\n",
    "        data_dict_processed = preprocess(data_dict)\n",
    "        X=data_dict_processed[\"image\"]\n",
    "        X=X.expand(1,X.shape[0],X.shape[1],X.shape[2],X.shape[3])\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = self(X.to(self.Device))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(unet.UNet3D,Engine):\n",
    "    def __init__(self):\n",
    "        Engine.__init__(self)\n",
    "        unet.UNet3D.__init__(self,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss= DiceLoss() \n",
      "\n",
      "Optimizer= Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ") \n",
      "\n",
      "Metrics= ['dice_score', 'loss'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model=NeuralNetwork()\n",
    "Model.Compile(loss= losses.loss_function(\"DiceLoss\"), optimizer= torch.optim.Adam(Model.parameters()), metrics=['dice_score','loss'])\n",
    "Model.CompileStatus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/dataset\n"
     ]
    }
   ],
   "source": [
    "Paths = {\"Barbary\":\"C:/dataset\", }\n",
    "Model.LoadData(Paths=Paths,dataset_name=\"Barbary\",transformation_flag=True,transformation=[64,256,256],batchsize=1,test_valid_split=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Shape of Training Features: (1, 1, 64, 256, 256) torch.float32\n",
      "Batch Shape of Training Labels: (1, 1, 64, 256, 256) torch.float32\n"
     ]
    }
   ],
   "source": [
    "Model.DataStatus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.978833        [    1/    1]\n",
      "Dice Score: 0.021167  [    1/    1]\n"
     ]
    }
   ],
   "source": [
    "Model.Fit(1) #one epoch on one input with transformation [64,256,256] took 7 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.954065\n",
      "Dice Score: 0.045935\n"
     ]
    }
   ],
   "source": [
    "Model.Evaluate_train() #evaluation on one input with transformation [64,256,256] took 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model.Evaluate_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 64, 256, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImagePath=\"C:/dataset/Path/liver-orig002.nii\"\n",
    "output=Model.Predict(ImagePath)\n",
    "output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
